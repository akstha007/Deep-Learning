{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"color: #2590c2; text-align: center;\">\n",
    "<span style=\"font-size:18pt;\"><b>ST: DEEP LEARNING</b></span><br/>\n",
    "<span>(CS 696-04) (SM18)</span><br/><br/>\n",
    "<span><b>Homework 3</b></span><br/><br/>\n",
    "<span>Submitted By</span><br/>\n",
    "<span>Ashok Kumar Shrestha</span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4><u>Tasks:</u></h4><br/>\n",
    "<span>In homework 3, you are asked to implement either your homework 1 or your homework 2 using tensorflow, keras or PyTorch.<span><br/>\n",
    "<span>Please also submit a report on Wednesday in class. </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Implementation:</h4><br/>\n",
    "<span>Implementing Homework-2 in Keras</span><br/>\n",
    "<h4>Testing results:</h4><br/>\n",
    "<div style=\"width: 700px;height:140px;\">\n",
    "    <div style=\"float: left;\">\n",
    "        <b>Data: CIFAR10</b><br/>\n",
    "        batch_size = 512<br/>\n",
    "        epochs = 15<br/>\n",
    "        Train loss: 0.5120<br/>\n",
    "        Train accuracy: 82.75 %<br/>\n",
    "        Test loss: 0.9040<br/>\n",
    "        Test accuracy: 70.55 %<br/>\n",
    "    </div>\n",
    "    <div style=\"float: right;\">\n",
    "        <b>Data: MNIST</b><br/>\n",
    "        batch_size = 512<br/>\n",
    "        epochs = 2<br/>\n",
    "        Train loss: 0.0638<br/>\n",
    "        Train accuracy: 98.09 %<br/>\n",
    "        Test loss: 0.0416<br/>\n",
    "        Test accuracy: 98.67 %\n",
    "    </div>\n",
    "    \n",
    "</div>\n",
    "<h4> CIFAR10:</h4>\n",
    "<div style=\"width: 800px;height:200px;\">\n",
    "    <img src=\"img/cost_vs_epochs.png\" style=\"height: 200px;float: left;\"/>\n",
    "    <img src=\"img/accuracy_vs_epochs.png\" style=\"height: 200px;float: right;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>\n",
    "Code:\n",
    "</b><br/>\n",
    "<span>\n",
    "Read data sets (MNIST and CIFAR-10) from the file.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Read Data sets: MNIST and CIFAR-10\n",
    "-----------------------------------------------\n",
    "Parameters:\n",
    "===========\n",
    "file_name: file name to read\n",
    "\n",
    "Return:\n",
    "=======\n",
    "train_img, test_img, train_lbl, test_lbl values\n",
    "\"\"\"\n",
    "import cloudpickle as pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import _pickle as pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def get_CIFAR10_data(cifar10_dir, num_training=49000, num_validation=1000, num_test=1000):\n",
    "    # Load the raw CIFAR-10 data\n",
    "    X_train, y_train, X_test, y_test = load(cifar10_dir)\n",
    "\n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    X_train = X_train.astype(np.float64)\n",
    "    X_val = X_val.astype(np.float64)\n",
    "    X_test = X_test.astype(np.float64)\n",
    "\n",
    "    # Transpose so that channels come first\n",
    "    X_train = X_train.transpose(0, 3, 1, 2)\n",
    "    X_val = X_val.transpose(0, 3, 1, 2)\n",
    "    X_test = X_test.transpose(0, 3, 1, 2)\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    std = np.std(X_train)\n",
    "\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    X_train /= std\n",
    "    X_val /= std\n",
    "    X_test /= std\n",
    "    \n",
    "    return {\n",
    "        'X_train': X_train, 'y_train': y_train,\n",
    "        'X_val': X_val, 'y_val': y_val,\n",
    "        'X_test': X_test, 'y_test': y_test,\n",
    "        'mean': mean_image, 'std': std\n",
    "    }\n",
    "\n",
    "def load_CIFAR_batch(filename):\n",
    "    ''' load single batch of cifar '''\n",
    "    with open(filename, 'rb') as f:\n",
    "        datadict = pickle.load(f, encoding ='bytes')\n",
    "        X = datadict[b'data']\n",
    "        Y = datadict[b'labels']\n",
    "        X = X.reshape(10000, 3, 32, 32)\n",
    "        Y = np.array(Y)\n",
    "        return X, Y\n",
    "\n",
    "def get_CIFAR10(ROOT):\n",
    "    ''' load all of cifar '''\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for b in range(1, 6):\n",
    "        f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "        X, Y = load_CIFAR_batch(f)\n",
    "        xs.append(X)\n",
    "        ys.append(Y)\n",
    "    Xtr = np.concatenate(xs)\n",
    "    Ytr = np.concatenate(ys)\n",
    "    del X, Y\n",
    "    Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "    return Xtr, Xte, Ytr, Yte\n",
    "\n",
    "def load_mnist(data_file=\"mnist.data\", test_size=0.10, random_state=0):\n",
    "    mnist = pickle.load(open(data_file, \"rb\"))\n",
    "    \n",
    "    mnist['data'] = np.reshape(mnist['data'],(mnist['data'].shape[0],1,28,28))\n",
    "    return train_test_split(mnist['data'], mnist['target'], test_size=test_size,\n",
    "                            random_state=random_state)\n",
    "\n",
    "def load(file_name):\n",
    "    if file_name == \"mnist\":\n",
    "        return load_mnist(data_file=\"mnist.data\", test_size=0.2, random_state=42)\n",
    "    \n",
    "    elif file_name == \"cifar10\":\n",
    "        return get_CIFAR10(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Main Program:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import cifar10\n",
    "from keras import backend as K\n",
    "K.set_image_dim_ordering('th')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_graph(epoch, history, title=\"Cost vs Epoch\",xlabel=\"Epochs\",ylabel=\"Training Cost\",image_name=\"cost_vs_epochs.png\"):\n",
    "        epochs = range(epoch)\n",
    "        \n",
    "        epochs = np.reshape(epochs,(-1,1))\n",
    "        history = np.reshape(history,(-1,1)) *100\n",
    "        \n",
    "        plt.plot(epochs, history,\"r--\")\n",
    "        plt.title(title)\n",
    "        plt.xlabel(xlabel)\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.savefig(image_name)\n",
    "        plt.show()\n",
    "\n",
    "#Read data from Keras' datasets\n",
    "def read_data_keras(file=\"mnist\"):\n",
    "    if file==\"mnist\":\n",
    "        (X_train, Y_train), (X_test, Y_test) = mnist.load_data()\n",
    "        c = 1\n",
    "        w,h = X_train.shape[1:]\n",
    "        print(\"MNIST data loaded.\")\n",
    "    elif file==\"cifar10\":\n",
    "        (X_train, Y_train), (X_test, Y_test) = cifar10.load_data()\n",
    "        c,w,h = X_train.shape[1:]\n",
    "        print(\"CIFAR data loaded.\")\n",
    "    \n",
    "    X_train = X_train.reshape(X_train.shape[0], c,w,h)\n",
    "    X_test = X_test.reshape(X_test.shape[0], c,w,h)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "    Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "    Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "    \n",
    "    return (X_train, Y_train), (X_test, Y_test)\n",
    "\n",
    "#Read data from dataset files provided\n",
    "def read_data_files(file=\"mnist\"):\n",
    "    if file==\"mnist\":\n",
    "        X_train, X_test, Y_train, Y_test = load(file_name=file)\n",
    "        print(\"MNIST data loaded.\")\n",
    "    elif file==\"cifar10\":\n",
    "        X_train, X_test, Y_train, Y_test = load(file_name=file)\n",
    "        print(\"CIFAR data loaded.\")\n",
    "    \n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "    Y_train = np_utils.to_categorical(Y_train, 10)\n",
    "    Y_test = np_utils.to_categorical(Y_test, 10)\n",
    "    \n",
    "    return (X_train, Y_train), (X_test, Y_test)\n",
    "\n",
    "def main(file=\"mnist\", batch_size = 512, epochs = 10):\n",
    "    print(\"Starting Network...\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"Reading Data sets...\")\n",
    "    \n",
    "    #(X_train, Y_train), (X_test, Y_test) = read_data_keras(file)\n",
    "    (X_train, Y_train), (X_test, Y_test) = read_data_files(file)\n",
    "    \n",
    "    input_shape = X_train.shape[1:]\n",
    "    num_classes = 10\n",
    "    \n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"Begin Training...\")\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),\n",
    "                     activation='relu',\n",
    "                     input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1000, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1)\n",
    "    \n",
    "    print(\"End Training.\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print(\"Begin Testing...\")\n",
    "    \n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    test_loss = score[0]\n",
    "    test_accuracy = score[1]*100\n",
    "    \n",
    "    print(\"End Testing.\")\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    \n",
    "    print('Training Accuracy: {0}'.format(test_loss))\n",
    "    print('Test Accuracy: {0:0.2f} %'.format(test_accuracy))\n",
    "    \n",
    "    show_graph(epochs, history.history['loss'], \n",
    "               title=\"Cost vs Epoch\",\n",
    "               xlabel=\"Epochs\",\n",
    "               ylabel=\"Training Cost\",\n",
    "               image_name=\"cost_vs_epochs.png\")\n",
    "    \n",
    "    show_graph(epochs, history.history['acc'], \n",
    "               title=\"Accuracy vs Epoch\",\n",
    "               xlabel=\"Epochs\",\n",
    "               ylabel=\"Accuracy\",\n",
    "               image_name=\"accuracy_vs_epochs.png\")\n",
    "\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    main(file=\"cifar10\", batch_size = 512, epochs = 15)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
